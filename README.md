## Learn2Perturb: a noise injection method for adversarial robustness

(Pytorch)

<span align="center"><img src="teaser.png" alt="" width="800"/></span>

This repository contains an implementation corresponing to:
The full name

Please cite as:

    @inproceedings{
    }

This repository includes PyTorch implementation of:

    <ul> 
        <li> Adversarial attacks 
            <ol>
                <li>FGSM</li>
                <li>PGD</li>
                <li>C&W</li>
                <li>EOT</li>
                <li>one-pixel</li>
            </ol>
        </li>
            
        <li>Baseline models used in experiments</li>
        
        <li>Learn2Perturb Modules</li>
        
    </ul>

